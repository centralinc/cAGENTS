---
name: agents-from-agentsmd
description: Imported from AGENTS.md
alwaysApply: true
when:
  target: ["agents-md"]
order: 10
---
<!--
This file is auto-generated by cAGENTS. Do not edit directly.

To update: run `cagents build`
For file-specific context: run `cagents context <filename>`
-->

<!--
This file is auto-generated by cAGENTS. Do not edit directly.

To update: run `cagents build`
For file-specific context: run `cagents context <filename>`
-->

<!--
This file is auto-generated by cAGENTS. Do not edit directly.

To update: run `cagents build`
For file-specific context: run `cagents context <filename>`
-->

## Project {project}
current branch: {branch}

- ‚úÖ Interactive CLI with beautiful output
- ‚úÖ Cursor support and comprehensive validation
- ‚úÖ All commands fully functional

## Core Development Requirements

### 1. STRICT TDD (Test-Driven Development)

**ALWAYS write tests BEFORE implementation:**

```bash
# ‚ùå WRONG: Code first, test later
1. Write function
2. Test it manually
3. Maybe add test

# ‚úÖ CORRECT: Test first, code second
1. Write FAILING test
2. Run test (verify it fails)
3. Implement minimal code
4. Run test (verify it passes)
5. Run ALL tests
6. Refactor if needed
```

**Every feature MUST have tests:**
- New command? ‚Üí Integration test in `crates/cagents-core/tests/`
- New function? ‚Üí Unit test in module `#[cfg(test)]`
- Bug fix? ‚Üí Test that reproduces bug first
- Refactor? ‚Üí Tests stay green throughout

**Test command:**
```bash
cargo test --workspace -- --test-threads=1
```

### 2. Task Tracking with TodoWrite

**ALWAYS use TodoWrite to track work:**

```javascript
// Start of milestone/feature
TodoWrite([
  {content: "Write failing test for X", status: "in_progress", activeForm: "Writing test"},
  {content: "Implement X", status: "pending", activeForm: "Implementing"},
  {content: "Verify tests pass", status: "pending", activeForm: "Verifying tests"},
  {content: "Update docs", status: "pending", activeForm: "Updating docs"},
  {content: "Commit", status: "pending", activeForm: "Committing"}
])
```

**Mark completed as you finish each task!**

### 3. Version Management

**During Beta (0.0.x): Patch versions only**
- We are currently in beta testing
- **Only increment patch version** for all changes (0.0.1 ‚Üí 0.0.2)
- First stable release will be 0.1.0

**After Beta (0.1.0+): Standard Semver**
- New command? ‚Üí **Minor** (0.1.0 ‚Üí 0.2.0)
- New feature? ‚Üí **Minor**
- Bug fix only? ‚Üí **Patch** (0.1.0 ‚Üí 0.1.1)
- Breaking change? ‚Üí **Major** (0.1.0 ‚Üí 1.0.0)

**Files to update (3 required):**
1. `crates/cagents-core/Cargo.toml`
2. `crates/cagents-cli/Cargo.toml`
3. `packages/cagents/package.json`
4. `CHANGELOG.md` (required)

### 4. Commit Guidelines

**When to commit:**
- After completing a Beads task (bd close <task-id>)
- After implementing a complete feature with tests
- After fixing a bug with tests
- After significant refactoring

**What to include in commits:**
- All test files (unit + integration)
- Implementation changes
- Updated CHANGELOG.md
- Version bumps in manifests
- Documentation updates if needed

**Commit message format:**
```
<type>: <short description>

<detailed description with bullet points>

Features/Changes:
- Feature 1
- Feature 2

Test Coverage:
- X tests passing (was Y, +Z new)

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)
via [Happy](https://happy.engineering)

Co-Authored-By: Claude <noreply@anthropic.com>
Co-Authored-By: Happy <yesreply@happy.engineering>
```

## Development Workflow

### For Every Task (Checklist)

- [ ] Create TodoWrite list with all steps
- [ ] Write FAILING test first (TDD)
- [ ] Implement minimal code
- [ ] Verify test passes
- [ ] Run full test suite (`cargo test --workspace -- --test-threads=1`)
- [ ] Bump patch version in 3 manifest files (during beta)
- [ ] Update CHANGELOG.md with changes
- [ ] Mark todos completed
- [ ] Close Beads task (`bd close <task-id> --reason "..."`)
- [ ] **Commit immediately** after task completion

### Test Structure

**Unit tests:**
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_function_name_scenario() {
        let input = "test";
        let result = function_name(input);
        assert_eq!(result, expected);
    }
}
```

**Integration tests:**
```rust
use serial_test::serial;

#[test]
#[serial]  // Required for directory-changing tests
fn test_end_to_end_feature() {
    let tmp = tempfile::TempDir::new().unwrap();
    // ...
}
```

## Build Commands

```bash
# Build
cargo build --workspace

# Test (REQUIRED before commits)
cargo test --workspace -- --test-threads=1

# Format & lint
cargo fmt
cargo clippy -- -D warnings

# Release build
cargo build --workspace --release
```

## Testing Requirements

**Test Coverage Goals:**
- Every module has unit tests
- Every command has integration test
- Edge cases covered
- Error paths tested

**Current: 91 tests passing**

**Test Guidelines:**
1. **Isolation** - No dependencies between tests
2. **Repeatability** - Same result every time
3. **Fast** - Quick execution (< 1s per test)
4. **Clear** - Easy to understand
5. **Serial** - Use `#[serial]` for global state changes

**Running tests:**
```bash
cargo test --workspace -- --test-threads=1
cargo test test_name -- --nocapture
```

## Repository Structure

```
crates/
  cagents-core/     - Core library
  cagents-cli/      - CLI binary
packages/
  cagents/          - pnpm wrapper
docs/               - Documentation
examples/           - Examples
cAGENTS/            - Self-documentation setup
```

## Non-Negotiable Rules

1. ‚ùå NO implementation without tests
2. ‚ùå NO commits without full test suite passing
3. ‚ùå NO version bumps without CHANGELOG
4. ‚ùå NO work without TodoWrite tracking
5. ‚úÖ YES to TDD always (test ‚Üí code ‚Üí refactor)

Violating these rules creates technical debt.

## Questions?

- Architecture details ‚Üí See `CLAUDE.md`
- Feature roadmap ‚Üí See `docs/ROADMAP.md`
- Current progress ‚Üí See `PROGRESS.md`

# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**.cAGENTS** is a cross-platform generator for `AGENTS.md` and compatible rule formats (e.g., Cursor `.mdc`). It composes rule files (Markdown + YAML front-matter), renders them with a BYOC (Bring-Your-Own-Compiler) engine, and writes context-scoped outputs at the repo root and nested directories.

This is a hybrid monorepo with:
- **Rust workspace** (`crates/`) - The fast, deterministic core
- **pnpm workspace** (`packages/`) - Thin TypeScript wrapper for npm distribution

## Build Commands

### Rust workspace
```bash
# Build all crates
cargo build --workspace

# Build with locked dependencies
cargo build --workspace --locked

# Run CLI directly
./target/debug/cagents --help
```

### Node wrapper (local development)
```bash
# Install all pnpm dependencies
pnpm -w i

# Build Node wrapper
pnpm --filter cagents run build

# Or build everything recursively
pnpm -w -r build

# Run via pnpm wrapper
pnpm cagents --help
```

### Testing
```bash
# Rust tests (runs in parallel by default)
cargo test --workspace

# Run tests sequentially (useful for debugging)
cargo test --workspace -- --test-threads=1

# Format and lint Rust
cargo fmt
cargo clippy -- -D warnings

# Format TypeScript
pnpm -w run fmt
```

**Note:** Tests automatically disable interactive prompts via multiple detection methods:
- Compile-time `cfg!(test)` flag (for unit tests)
- Thread name pattern matching (detects `test_` in thread name)
- Manual override via `CAGENTS_TEST=1` environment variable

If you still see interactive prompts during tests, run with:
```bash
CAGENTS_TEST=1 cargo test --workspace
```

## CLI Commands

The CLI provides these subcommands (note: currently stubs, see implementation in `crates/cagents-core/src/lib.rs`):

```bash
cagents init --preset=mdc
cagents build --env=cloud --role=backend [--out .]
cagents export --target cursor
cagents lint
cagents explain <path>
```

## Architecture Overview

### Core (Rust) - `crates/cagents-core/`

The pipeline flows through these modules (see `crates/cagents-core/src/lib.rs`):

1. **config** - TOML config loader (project-local `.agentscribe/config.toml` + user-level `~/.cagents/config.toml`)
2. **loader** - Rule discovery (front-matter + body parsing)
3. **model** - Data structures for `ProjectConfig`, `RuleFrontmatter`, scoping (`When`), merge strategies
4. **planner** - Determines which rules apply based on globs, `alwaysApply`, `when` conditions (env/role/language), order, and extends
5. **render** - Template rendering via BYOB command adapters
6. **adapters/** - External command protocol via stdin/stdout JSON (built-in engines removed in M11)
7. **merge** - Section-aware rule merging
8. **writers/** - Output to `AGENTS.md` and Cursor `.mdc` formats

### Wrapper (TypeScript) - `packages/cagents/`

Thin pnpm package that downloads/executes prebuilt binaries in real releases. For local development, the postinstall script warns to build from source. Exposes a programmatic API.

### Configuration

Config files use TOML with these key sections:
- `[paths]` - `templatesDir`, `outputRoot`, `cursorRulesDir`
- `[defaults]` - `engine` (e.g. `command:python3 tools/render.py`), `targets`, `order`
- `[variables]` - `static`, `env`, `command` (for template data)
- `[execution]` - `shell`, `timeoutMs`, `allowCommands`

Rule templates have YAML front-matter with fields like `engine`, `globs`, `alwaysApply`, `when`, `order`, `extends`, `targets`, `merge`.

### BYOC Compiler Protocol

External compilers (e.g., Python Jinja2, Node MDX) communicate via JSON:
- **IN (stdin)**: `{ templateSource, templatePath, data, frontmatter, cwd }`
- **OUT (stdout)**: `{ content, diagnostics? }`

See `docs/COMPILERS.md` and `crates/cagents-core/src/adapters/command.rs`.

## Development Workflow

### STRICT TDD REQUIREMENT

**You MUST follow Test-Driven Development for ALL changes:**

1. **Write failing test FIRST**
   ```bash
   # Create test in appropriate location
   # - crates/cagents-core/tests/ for integration tests
   # - Module #[cfg(test)] for unit tests

   cargo test <test_name>
   # Should FAIL initially
   ```

2. **Implement minimal code to pass**
   ```rust
   // Add just enough code to make test pass
   ```

3. **Verify test passes**
   ```bash
   cargo test <test_name>
   # Should PASS now
   ```

4. **Run full test suite**
   ```bash
   cargo test --workspace -- --test-threads=1
   # ALL tests should pass
   ```

5. **Refactor if needed** (keeping tests green)

**Examples:**
- Adding new command? Write integration test first
- New validation rule? Write lint test first
- New preset? Write init test first

### Task Tracking Requirement

**You MUST use TodoWrite for ALL work:**

1. **Start of work:** Create todo list with all slices
2. **During work:** Update status (in_progress ‚Üí completed)
3. **After each slice:** Mark completed and move to next
4. **Before commits:** Ensure todos reflect actual work

**Example:**
```javascript
TodoWrite([
  {content: "Write failing test for feature X", status: "in_progress"},
  {content: "Implement feature X", status: "pending"},
  {content: "Verify all tests pass", status: "pending"},
  {content: "Commit changes", status: "pending"}
])
```

### Test Locations

**Unit Tests:**
- Place in same file as code: `#[cfg(test)] mod tests { ... }`
- Test individual functions in isolation

**Integration Tests:**
- `crates/cagents-core/tests/*.rs` - Core functionality
- `crates/cagents-cli/tests/*.rs` - CLI commands

**Test Naming:**
```rust
#[test]
fn test_<feature>_<scenario>() {
    // Arrange
    let input = setup_test_data();

    // Act
    let result = function_under_test(input);

    // Assert
    assert_eq!(result, expected);
}
```

### Example TDD Session

```bash
# 1. Create test
cat > crates/cagents-core/tests/new_feature.rs << 'EOF'
#[test]
fn test_new_feature_works() {
    let result = new_function();
    assert_eq!(result, expected_value);
}
EOF

# 2. Run test (should fail)
cargo test test_new_feature_works
# ‚ùå FAILS: function not found

# 3. Implement
# Add function to appropriate module

# 4. Run test (should pass)
cargo test test_new_feature_works
# ‚úÖ PASSES

# 5. Run all tests
cargo test --workspace -- --test-threads=1
# ‚úÖ ALL PASS

# 6. Commit
git add -A
git commit -m "Add new_feature with tests"
```

### Non-Negotiable Rules

1. **No implementation without tests**
2. **No commits without running full test suite**
3. **No version bumps without CHANGELOG update**
4. **No work without TodoWrite tracking**
5. **TDD always: test first, code second**

Violating these rules will result in technical debt and bugs.

## Repository Structure

```
crates/
  cagents-core/     - Library (planning, renderers, writers)
  cagents-cli/      - CLI binary entry point
packages/
  cagents/          - pnpm wrapper (downloads binary in releases)
docs/               - PRD, architecture, config, CLI, compiler protocol, roadmap
examples/           - Runnable samples
```

## Tasks and planning
We track work in Beads instead of Markdown. Run \`bd quickstart\` to see how.

<!--
This file is auto-generated by cAGENTS. Do not edit directly.

To update: run `cagents build`
For file-specific context: run `cagents context <filename>`
-->

<!--
This file is auto-generated by cAGENTS. Do not edit directly.

To update: run `cagents build`
For file-specific context: run `cagents context <filename>`
-->

## Project {project}
current branch: {branch}

- ‚úÖ Interactive CLI with beautiful output
- ‚úÖ Cursor support and comprehensive validation
- ‚úÖ All commands fully functional

## Core Development Requirements

### 1. STRICT TDD (Test-Driven Development)

**ALWAYS write tests BEFORE implementation:**

```bash
# ‚ùå WRONG: Code first, test later
1. Write function
2. Test it manually
3. Maybe add test

# ‚úÖ CORRECT: Test first, code second
1. Write FAILING test
2. Run test (verify it fails)
3. Implement minimal code
4. Run test (verify it passes)
5. Run ALL tests
6. Refactor if needed
```

**Every feature MUST have tests:**
- New command? ‚Üí Integration test in `crates/cagents-core/tests/`
- New function? ‚Üí Unit test in module `#[cfg(test)]`
- Bug fix? ‚Üí Test that reproduces bug first
- Refactor? ‚Üí Tests stay green throughout

**Test command:**
```bash
cargo test --workspace -- --test-threads=1
```

### 2. Task Tracking with TodoWrite

**ALWAYS use TodoWrite to track work:**

```javascript
// Start of milestone/feature
TodoWrite([
  {content: "Write failing test for X", status: "in_progress", activeForm: "Writing test"},
  {content: "Implement X", status: "pending", activeForm: "Implementing"},
  {content: "Verify tests pass", status: "pending", activeForm: "Verifying tests"},
  {content: "Update docs", status: "pending", activeForm: "Updating docs"},
  {content: "Commit", status: "pending", activeForm: "Committing"}
])
```

**Mark completed as you finish each task!**

### 3. Version Management

**During Beta (0.0.x): Patch versions only**
- We are currently in beta testing
- **Only increment patch version** for all changes (0.0.1 ‚Üí 0.0.2)
- First stable release will be 0.1.0

**After Beta (0.1.0+): Standard Semver**
- New command? ‚Üí **Minor** (0.1.0 ‚Üí 0.2.0)
- New feature? ‚Üí **Minor**
- Bug fix only? ‚Üí **Patch** (0.1.0 ‚Üí 0.1.1)
- Breaking change? ‚Üí **Major** (0.1.0 ‚Üí 1.0.0)

**Files to update (3 required):**
1. `crates/cagents-core/Cargo.toml`
2. `crates/cagents-cli/Cargo.toml`
3. `packages/cagents/package.json`
4. `CHANGELOG.md` (required)

### 4. Commit Guidelines

**When to commit:**
- After completing a Beads task (bd close <task-id>)
- After implementing a complete feature with tests
- After fixing a bug with tests
- After significant refactoring

**What to include in commits:**
- All test files (unit + integration)
- Implementation changes
- Updated CHANGELOG.md
- Version bumps in manifests
- Documentation updates if needed

**Commit message format:**
```
<type>: <short description>

<detailed description with bullet points>

Features/Changes:
- Feature 1
- Feature 2

Test Coverage:
- X tests passing (was Y, +Z new)

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)
via [Happy](https://happy.engineering)

Co-Authored-By: Claude <noreply@anthropic.com>
Co-Authored-By: Happy <yesreply@happy.engineering>
```

## Development Workflow

### For Every Task (Checklist)

- [ ] Create TodoWrite list with all steps
- [ ] Write FAILING test first (TDD)
- [ ] Implement minimal code
- [ ] Verify test passes
- [ ] Run full test suite (`cargo test --workspace -- --test-threads=1`)
- [ ] Bump patch version in 3 manifest files (during beta)
- [ ] Update CHANGELOG.md with changes
- [ ] Mark todos completed
- [ ] Close Beads task (`bd close <task-id> --reason "..."`)
- [ ] **Commit immediately** after task completion

### Test Structure

**Unit tests:**
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_function_name_scenario() {
        let input = "test";
        let result = function_name(input);
        assert_eq!(result, expected);
    }
}
```

**Integration tests:**
```rust
use serial_test::serial;

#[test]
#[serial]  // Required for directory-changing tests
fn test_end_to_end_feature() {
    let tmp = tempfile::TempDir::new().unwrap();
    // ...
}
```

## Build Commands

```bash
# Build
cargo build --workspace

# Test (REQUIRED before commits)
cargo test --workspace -- --test-threads=1

# Format & lint
cargo fmt
cargo clippy -- -D warnings

# Release build
cargo build --workspace --release
```

## Testing Requirements

**Test Coverage Goals:**
- Every module has unit tests
- Every command has integration test
- Edge cases covered
- Error paths tested

**Current: 91 tests passing**

**Test Guidelines:**
1. **Isolation** - No dependencies between tests
2. **Repeatability** - Same result every time
3. **Fast** - Quick execution (< 1s per test)
4. **Clear** - Easy to understand
5. **Serial** - Use `#[serial]` for global state changes

**Running tests:**
```bash
cargo test --workspace -- --test-threads=1
cargo test test_name -- --nocapture
```

## Repository Structure

```
crates/
  cagents-core/     - Core library
  cagents-cli/      - CLI binary
packages/
  cagents/          - pnpm wrapper
docs/               - Documentation
examples/           - Examples
cAGENTS/            - Self-documentation setup
```

## Non-Negotiable Rules

1. ‚ùå NO implementation without tests
2. ‚ùå NO commits without full test suite passing
3. ‚ùå NO version bumps without CHANGELOG
4. ‚ùå NO work without TodoWrite tracking
5. ‚úÖ YES to TDD always (test ‚Üí code ‚Üí refactor)

Violating these rules creates technical debt.

## Questions?

- Architecture details ‚Üí See `CLAUDE.md`
- Feature roadmap ‚Üí See `docs/ROADMAP.md`
- Current progress ‚Üí See `PROGRESS.md`

# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**.cAGENTS** is a cross-platform generator for `AGENTS.md` and compatible rule formats (e.g., Cursor `.mdc`). It composes rule files (Markdown + YAML front-matter), renders them with a BYOC (Bring-Your-Own-Compiler) engine, and writes context-scoped outputs at the repo root and nested directories.

This is a hybrid monorepo with:
- **Rust workspace** (`crates/`) - The fast, deterministic core
- **pnpm workspace** (`packages/`) - Thin TypeScript wrapper for npm distribution

## Build Commands

### Rust workspace
```bash
# Build all crates
cargo build --workspace

# Build with locked dependencies
cargo build --workspace --locked

# Run CLI directly
./target/debug/cagents --help
```

### Node wrapper (local development)
```bash
# Install all pnpm dependencies
pnpm -w i

# Build Node wrapper
pnpm --filter cagents run build

# Or build everything recursively
pnpm -w -r build

# Run via pnpm wrapper
pnpm cagents --help
```

### Testing
```bash
# Rust tests (runs in parallel by default)
cargo test --workspace

# Run tests sequentially (useful for debugging)
cargo test --workspace -- --test-threads=1

# Format and lint Rust
cargo fmt
cargo clippy -- -D warnings

# Format TypeScript
pnpm -w run fmt
```

**Note:** Tests automatically disable interactive prompts via multiple detection methods:
- Compile-time `cfg!(test)` flag (for unit tests)
- Thread name pattern matching (detects `test_` in thread name)
- Manual override via `CAGENTS_TEST=1` environment variable

If you still see interactive prompts during tests, run with:
```bash
CAGENTS_TEST=1 cargo test --workspace
```

## CLI Commands

The CLI provides these subcommands (note: currently stubs, see implementation in `crates/cagents-core/src/lib.rs`):

```bash
cagents init --preset=mdc
cagents build --env=cloud --role=backend [--out .]
cagents export --target cursor
cagents lint
cagents explain <path>
```

## Architecture Overview

### Core (Rust) - `crates/cagents-core/`

The pipeline flows through these modules (see `crates/cagents-core/src/lib.rs`):

1. **config** - TOML config loader (project-local `.agentscribe/config.toml` + user-level `~/.cagents/config.toml`)
2. **loader** - Rule discovery (front-matter + body parsing)
3. **model** - Data structures for `ProjectConfig`, `RuleFrontmatter`, scoping (`When`), merge strategies
4. **planner** - Determines which rules apply based on globs, `alwaysApply`, `when` conditions (env/role/language), order, and extends
5. **render** - Template rendering via BYOB command adapters
6. **adapters/** - External command protocol via stdin/stdout JSON (built-in engines removed in M11)
7. **merge** - Section-aware rule merging
8. **writers/** - Output to `AGENTS.md` and Cursor `.mdc` formats

### Wrapper (TypeScript) - `packages/cagents/`

Thin pnpm package that downloads/executes prebuilt binaries in real releases. For local development, the postinstall script warns to build from source. Exposes a programmatic API.

### Configuration

Config files use TOML with these key sections:
- `[paths]` - `templatesDir`, `outputRoot`, `cursorRulesDir`
- `[defaults]` - `engine` (e.g. `command:python3 tools/render.py`), `targets`, `order`
- `[variables]` - `static`, `env`, `command` (for template data)
- `[execution]` - `shell`, `timeoutMs`, `allowCommands`

Rule templates have YAML front-matter with fields like `engine`, `globs`, `alwaysApply`, `when`, `order`, `extends`, `targets`, `merge`.

### BYOC Compiler Protocol

External compilers (e.g., Python Jinja2, Node MDX) communicate via JSON:
- **IN (stdin)**: `{ templateSource, templatePath, data, frontmatter, cwd }`
- **OUT (stdout)**: `{ content, diagnostics? }`

See `docs/COMPILERS.md` and `crates/cagents-core/src/adapters/command.rs`.

## Development Workflow

### STRICT TDD REQUIREMENT

**You MUST follow Test-Driven Development for ALL changes:**

1. **Write failing test FIRST**
   ```bash
   # Create test in appropriate location
   # - crates/cagents-core/tests/ for integration tests
   # - Module #[cfg(test)] for unit tests

   cargo test <test_name>
   # Should FAIL initially
   ```

2. **Implement minimal code to pass**
   ```rust
   // Add just enough code to make test pass
   ```

3. **Verify test passes**
   ```bash
   cargo test <test_name>
   # Should PASS now
   ```

4. **Run full test suite**
   ```bash
   cargo test --workspace -- --test-threads=1
   # ALL tests should pass
   ```

5. **Refactor if needed** (keeping tests green)

**Examples:**
- Adding new command? Write integration test first
- New validation rule? Write lint test first
- New preset? Write init test first

### Task Tracking Requirement

**You MUST use TodoWrite for ALL work:**

1. **Start of work:** Create todo list with all slices
2. **During work:** Update status (in_progress ‚Üí completed)
3. **After each slice:** Mark completed and move to next
4. **Before commits:** Ensure todos reflect actual work

**Example:**
```javascript
TodoWrite([
  {content: "Write failing test for feature X", status: "in_progress"},
  {content: "Implement feature X", status: "pending"},
  {content: "Verify all tests pass", status: "pending"},
  {content: "Commit changes", status: "pending"}
])
```

### Test Locations

**Unit Tests:**
- Place in same file as code: `#[cfg(test)] mod tests { ... }`
- Test individual functions in isolation

**Integration Tests:**
- `crates/cagents-core/tests/*.rs` - Core functionality
- `crates/cagents-cli/tests/*.rs` - CLI commands

**Test Naming:**
```rust
#[test]
fn test_<feature>_<scenario>() {
    // Arrange
    let input = setup_test_data();

    // Act
    let result = function_under_test(input);

    // Assert
    assert_eq!(result, expected);
}
```

### Example TDD Session

```bash
# 1. Create test
cat > crates/cagents-core/tests/new_feature.rs << 'EOF'
#[test]
fn test_new_feature_works() {
    let result = new_function();
    assert_eq!(result, expected_value);
}
EOF

# 2. Run test (should fail)
cargo test test_new_feature_works
# ‚ùå FAILS: function not found

# 3. Implement
# Add function to appropriate module

# 4. Run test (should pass)
cargo test test_new_feature_works
# ‚úÖ PASSES

# 5. Run all tests
cargo test --workspace -- --test-threads=1
# ‚úÖ ALL PASS

# 6. Commit
git add -A
git commit -m "Add new_feature with tests"
```

### Non-Negotiable Rules

1. **No implementation without tests**
2. **No commits without running full test suite**
3. **No version bumps without CHANGELOG update**
4. **No work without TodoWrite tracking**
5. **TDD always: test first, code second**

Violating these rules will result in technical debt and bugs.

## Repository Structure

```
crates/
  cagents-core/     - Library (planning, renderers, writers)
  cagents-cli/      - CLI binary entry point
packages/
  cagents/          - pnpm wrapper (downloads binary in releases)
docs/               - PRD, architecture, config, CLI, compiler protocol, roadmap
examples/           - Runnable samples
```

## Tasks and planning
We track work in Beads instead of Markdown. Run \`bd quickstart\` to see how.

# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**.cAGENTS** is a cross-platform generator for `AGENTS.md` and compatible rule formats (e.g., Cursor `.mdc`). It composes rule files (Markdown + YAML front-matter), renders them with a BYOC (Bring-Your-Own-Compiler) engine, and writes context-scoped outputs at the repo root and nested directories.

This is a hybrid monorepo with:
- **Rust workspace** (`crates/`) - The fast, deterministic core
- **pnpm workspace** (`packages/`) - Thin TypeScript wrapper for npm distribution

## Build Commands

### Rust workspace
```bash
# Build all crates
cargo build --workspace

# Build with locked dependencies
cargo build --workspace --locked

# Run CLI directly
./target/debug/cagents --help
```

### Node wrapper (local development)
```bash
# Install all pnpm dependencies
pnpm -w i

# Build Node wrapper
pnpm --filter cagents run build

# Or build everything recursively
pnpm -w -r build

# Run via pnpm wrapper
pnpm cagents --help
```

### Testing
```bash
# Rust tests (runs in parallel by default)
cargo test --workspace

# Run tests sequentially (useful for debugging)
cargo test --workspace -- --test-threads=1

# Format and lint Rust
cargo fmt
cargo clippy -- -D warnings

# Format TypeScript
pnpm -w run fmt
```

**Note:** Tests automatically disable interactive prompts via multiple detection methods:
- Compile-time `cfg!(test)` flag (for unit tests)
- Thread name pattern matching (detects `test_` in thread name)
- Manual override via `CAGENTS_TEST=1` environment variable

If you still see interactive prompts during tests, run with:
```bash
CAGENTS_TEST=1 cargo test --workspace
```

## CLI Commands

The CLI provides these subcommands (note: currently stubs, see implementation in `crates/cagents-core/src/lib.rs`):

```bash
cagents init --preset=mdc
cagents build --env=cloud --role=backend [--out .]
cagents export --target cursor
cagents lint
cagents explain <path>
```

## Architecture Overview

### Core (Rust) - `crates/cagents-core/`

The pipeline flows through these modules (see `crates/cagents-core/src/lib.rs`):

1. **config** - TOML config loader (project-local `.agentscribe/config.toml` + user-level `~/.cagents/config.toml`)
2. **loader** - Rule discovery (front-matter + body parsing)
3. **model** - Data structures for `ProjectConfig`, `RuleFrontmatter`, scoping (`When`), merge strategies
4. **planner** - Determines which rules apply based on globs, `alwaysApply`, `when` conditions (env/role/language), order, and extends
5. **render** - Template rendering via BYOB command adapters
6. **adapters/** - External command protocol via stdin/stdout JSON (built-in engines removed in M11)
7. **merge** - Section-aware rule merging
8. **writers/** - Output to `AGENTS.md` and Cursor `.mdc` formats

### Wrapper (TypeScript) - `packages/cagents/`

Thin pnpm package that downloads/executes prebuilt binaries in real releases. For local development, the postinstall script warns to build from source. Exposes a programmatic API.

### Configuration

Config files use TOML with these key sections:
- `[paths]` - `templatesDir`, `outputRoot`, `cursorRulesDir`
- `[defaults]` - `engine` (e.g. `command:python3 tools/render.py`), `targets`, `order`
- `[variables]` - `static`, `env`, `command` (for template data)
- `[execution]` - `shell`, `timeoutMs`, `allowCommands`

Rule templates have YAML front-matter with fields like `engine`, `globs`, `alwaysApply`, `when`, `order`, `extends`, `targets`, `merge`.

### BYOC Compiler Protocol

External compilers (e.g., Python Jinja2, Node MDX) communicate via JSON:
- **IN (stdin)**: `{ templateSource, templatePath, data, frontmatter, cwd }`
- **OUT (stdout)**: `{ content, diagnostics? }`

See `docs/COMPILERS.md` and `crates/cagents-core/src/adapters/command.rs`.

## Development Workflow

### STRICT TDD REQUIREMENT

**You MUST follow Test-Driven Development for ALL changes:**

1. **Write failing test FIRST**
   ```bash
   # Create test in appropriate location
   # - crates/cagents-core/tests/ for integration tests
   # - Module #[cfg(test)] for unit tests

   cargo test <test_name>
   # Should FAIL initially
   ```

2. **Implement minimal code to pass**
   ```rust
   // Add just enough code to make test pass
   ```

3. **Verify test passes**
   ```bash
   cargo test <test_name>
   # Should PASS now
   ```

4. **Run full test suite**
   ```bash
   cargo test --workspace -- --test-threads=1
   # ALL tests should pass
   ```

5. **Refactor if needed** (keeping tests green)

**Examples:**
- Adding new command? Write integration test first
- New validation rule? Write lint test first
- New preset? Write init test first

### Task Tracking Requirement

**You MUST use TodoWrite for ALL work:**

1. **Start of work:** Create todo list with all slices
2. **During work:** Update status (in_progress ‚Üí completed)
3. **After each slice:** Mark completed and move to next
4. **Before commits:** Ensure todos reflect actual work

**Example:**
```javascript
TodoWrite([
  {content: "Write failing test for feature X", status: "in_progress"},
  {content: "Implement feature X", status: "pending"},
  {content: "Verify all tests pass", status: "pending"},
  {content: "Commit changes", status: "pending"}
])
```

### Test Locations

**Unit Tests:**
- Place in same file as code: `#[cfg(test)] mod tests { ... }`
- Test individual functions in isolation

**Integration Tests:**
- `crates/cagents-core/tests/*.rs` - Core functionality
- `crates/cagents-cli/tests/*.rs` - CLI commands

**Test Naming:**
```rust
#[test]
fn test_<feature>_<scenario>() {
    // Arrange
    let input = setup_test_data();

    // Act
    let result = function_under_test(input);

    // Assert
    assert_eq!(result, expected);
}
```

### Example TDD Session

```bash
# 1. Create test
cat > crates/cagents-core/tests/new_feature.rs << 'EOF'
#[test]
fn test_new_feature_works() {
    let result = new_function();
    assert_eq!(result, expected_value);
}
EOF

# 2. Run test (should fail)
cargo test test_new_feature_works
# ‚ùå FAILS: function not found

# 3. Implement
# Add function to appropriate module

# 4. Run test (should pass)
cargo test test_new_feature_works
# ‚úÖ PASSES

# 5. Run all tests
cargo test --workspace -- --test-threads=1
# ‚úÖ ALL PASS

# 6. Commit
git add -A
git commit -m "Add new_feature with tests"
```

### Non-Negotiable Rules

1. **No implementation without tests**
2. **No commits without running full test suite**
3. **No version bumps without CHANGELOG update**
4. **No work without TodoWrite tracking**
5. **TDD always: test first, code second**

Violating these rules will result in technical debt and bugs.

## Repository Structure

```
crates/
  cagents-core/     - Library (planning, renderers, writers)
  cagents-cli/      - CLI binary entry point
packages/
  cagents/          - pnpm wrapper (downloads binary in releases)
docs/               - PRD, architecture, config, CLI, compiler protocol, roadmap
examples/           - Runnable samples
```

## Tasks and planning
We track work in Beads instead of Markdown. Run \`bd quickstart\` to see how.
